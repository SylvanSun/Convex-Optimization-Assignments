\documentclass[12pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{xfrac}
\usepackage{algorithm}
\usepackage{bbm}
\usepackage[noend]{algpseudocode}

\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}
\linespread{1.1}
 
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}

\lstdefinestyle{Python}{
    language        = Python,
    frame           = lines, 
    basicstyle      = \footnotesize,
    keywordstyle    = \color{blue},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}

% Edit these as appropriate
\newcommand\course{Stochastic Processes}
\newcommand\hwnumber{3}                  % <-- homework number
\newcommand\NetIDa{SUN Yilin}           % <-- NetID of person #1
\newcommand\NetIDb{520030910361}           % <-- NetID of person #2 (Comment this line out for problem sets)

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\NetIDa}
\lhead{\NetIDa\\\NetIDb}                 % <-- Comment this line out for problem sets (make sure you are person #1)
\chead{\textbf{\Large Homework \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}

\section{FTMC for countably infinite chains}

\subsection{}
To prove this, we only need to show $[F]+[A]+[I]$ implies $[PR]+[A]+[I]$.\newline
To show this, we only need to show $[F]+[I]$ implies $[PR]$, i.e.
a finite and irreducible markov chain is positive recurrent.\newline
\newline
Firstly, for a finite markov chain, there exists at least one recurrent state.
If not, all the states in this markov chain can only be visited finitely many times.
But this finite markov chain only contains finite states,
so when we visit infinitely many times this cannot be true.\\
Then if the markov chain is also irreducible, since recurrence is a class property,
the existence of a single recurrent state means this markov chain is recurrent.\\
\newline
Now we only need to show a finite irreducible recurrent markov chain is positive recurrent.
Similar to our proof in lecture notes, we know that positive recurrence and null recurrence are both class properties.
Then if the recurrent markov chain contains a null recurrent state, it is null recurrent itself.
Since $\sum_{j\in S}P_{ij}^{n}=1$ and there are only finite number of states,
it is impossible that $\lim_{n\to\infty}P_{ij}^{n}=0$ for all $j\in S$.
Thus this markov chain cannot be null recurrent. Then it can only be positive recurrent.\\
\newline
To sum up, a finite irreducible markov chain must be positive recurrent.
So the proposition in this problem about these two implications is correct.

\subsection{}
Denote $P(i,i')P(j,j')$ by $Q((i,j),(i',j'))$.
To prove $\Pr_{(i,j)}[T_{(k,k)}<\infty]=1$,
we only need to prove that $Q$ is positive recurrent.\\
To prove this, we first show that $Q$ has a stationary distribution.
Note that $P$ is positive recurrent and irreducible,
from what we have proven in class,
we know that $P$ must have a unique stationary distribution.
Denote the stationary distribution by $\pi$,
then we know that the stationary distribution of $Q$ is when it follows the distribution of $\pi$ coordinate-wisely.
So $Q$ has a unique stationary distribution.\\
Then we show that $Q$ is irreducible. 
For any $i,j,i',j'$, we want to find a $n$ such that $Q^{n}((i,j),(i',j'))=P^{n}(i,i')P^{n}(j,j')>0$.
Since $P$ is aperiodic and irreducible, for any $j,i'$ and sufficiently large $n$,
$P^{n}(j,i')>0$ always hold.
So the $n$ such that $Q^{n}((i,j),(i',j'))>0$ always exists.
Hence $Q$ is irreducible.\\
Now we show that for any markov chain, irreducible provided,
if the chain has a unique stationary distribution,
then it must be positive recurrent.
Let $N_{i}(n)$ be the number of visits of state $i$ in the first $n$ steps.
Since the markov chain is irreducible, 
the strong law of large numbers for markov chain shows that 
$$P_{j}\left[\lim_{n\to\infty}\frac{N_{i}(n)}{n}=\frac{1}{\mathbb{E}_{i}(T_i)}\right]=1$$
Denote the stationary distribution by $\pi$ and let $X_0\sim\pi$,
then by the bounded convergence theorem we have
$$\mathbb{E}_{X_0\sim\pi}\left[\frac{N_i(n)}{n}\right]=\sum_{t=1}^{n}\frac{\mathbb{E}_{X_0\sim\pi}\left[1_{\left[X_t=i\right]}\right]}{n}=n\frac{\pi(i)}{n}=\frac{1}{\mathbb{E}_i(T_i)}$$
Since the chain is irreducible, $\pi(i)>0$ for every $i$,
thus $\mathbb{E}_i(T_i)<\infty$ for every $i$,
i.e. the markov chain is positive recurrent.\\
Since $Q$ is such a markov chain irreducible with a unique stationary distribution,
it is positive recurrent.
Then it follows that $\Pr_{(i,j)}[T_{(k,k)}<\infty]=1$ for any $i,j,k\in\Omega$.

\subsection{}
We already know from class that $[I]+[PR]$ implies $[S]+[U]$.
So we only need to prove that the markov chain will converge if it is aperiodic.\\
We use total variance distance to describe the convergence. 
We want to show for any starting distribution $\mu_0$, 
the total variance distance of $\mu_t$ and stationary distribution $\pi$, $D_{TV}(\mu_t,\pi)$
goes to $0$ as $t$ goes to $\infty$.\\
Follow the instructions of finite case from class, 
we will use two markov chains with the same transition matrix $P$.
Suppose these two markov chains are $\{X_t\}$ and $\{Y_t\}$ where $Y_0\sim\pi$ yet $X_0\sim\mu_0$, an arbitrary distribution.\\
Now we construct a coupling $\omega_t$ of $\mu_t$ and $\pi$.
The coupling is the same as finite case in class.
Let $(X_t,Y_t)\sim\omega_t$, we construct $\omega_{t+1}$ by the following method.
If $X_t=Y_t$ for some $t\geq 0$, then let $X_{t'}=Y_{t'}$ for all $t'>t$. 
If not, we let $X_t$ and $Y_t$ go to $X_{t+1}$ and $Y_{t+1}$ independently.\\
The coupling lemma tells us that $D_{TV}(\mu_t,\pi)\leq\Pr(X_t\neq Y_t)$. 
And we have shown in class that with a finite markov chain 
$$\lim_{t\to\infty}\Pr(X_t\neq Y_t)=\lim_{t\to\infty}\sum_{x_{0},y_{0}}\mu_{0}(x_0)\pi(y_0)\Pr_{x_0,y_0}(X_t\neq Y_t)=0$$
Now we consider the countably infinite case. For our coupling the transition function before $X_t=Y_t$ is what we have defined in problem $1.2$, denoted by $Q$.
From what we have proven in problem $1.2$, $\Pr_{(i,j)}[T_{(k,k)}<\infty]=1$ for any $i,j,k\in\Omega$.
This means that the probability of $X_t$ "meets" $Y_t$ within finite time is 1,
which is equivalent to saying that $\lim_{t\to\infty}D_{TV}(\mu_t,\pi)=0$.
So such a positive recurrent countably infinite markov chain will converge to its unique stationary distribution.


\newpage
\section{A Randomized Algorithm for 3-SAT}
\subsection{}
We use the same notations as defined in class.
Similar to our analysis in class, 
if we repeat the random flipping operation for $2n^2$ times,
the lower bound for 
$$1-\Pr\left[\exists t\in [0,2n^2]\quad s.t.\quad Y_t=n\right]$$
is equal to 
$$\Pr\left[T_{Y_0\to n}>2n^2\right]\leq\frac{\mathbb{E}[T_{Y_0\to n}]}{2n^2}\leq\frac{1}{2}$$
Thus the probability that this algorithm is \textbf{not} correct 
after one iteration is $\frac{1}{2}$.
But we will run our algorithm 50 times, 
if after any iteration our algorithm gives a correct assignment,
then the algorithm is correct.
If none of the 50 iterations says the CNF is satisfiable,
then the probability of the CNF indeed being satisfiable is 
$(\frac{1}{2})^{50}$.
Thus the probability of our algorithm is correct is $1-(\frac{1}{2})^{50}$.

\subsection{}
Without loss of generality, assume we choose clause $c=x\vee y\vee z$ at round $t$.
Then we have $\sigma_t(x)=\sigma_t(y)=\sigma_t(z)=F$ where $F$ indicates that those variables are false.
And there are seven possible assignments of $\sigma(x),\sigma(y)$ and $\sigma(z)$,
of which three are only one of $x,y,z$ is $T$,
three are exactly two of $x,y,z$ are $T$,
one is all of $x,y,z$ are $T$.\\
In the first three cases $\Pr\left[X_{t+1}=X_{t}+1\right]=\frac{1}{3}$ and $\Pr\left[X_{t+1}=X_{t}-1\right]=\frac{2}{3}$.\\
In the middle trree cases  $\Pr\left[X_{t+1}=X_{t}+1\right]=\frac{2}{3}$ and $\Pr\left[X_{t+1}=X_{t}-1\right]=\frac{1}{3}$.\\
In the last case $\Pr\left[X_{t+1}=X_{t}+1\right]=1$ and $\Pr\left[X_{t+1}=X_{t}-1\right]=0$.\\
Thus we have $\Pr\left[X_{t+1}=X_{t}+1\right]\geq \frac{1}{3}$ and $\Pr\left[X_{t+1}=X_{t}-1\right]\leq\frac{2}{3}$.\\

\subsection{}
We use the same notations in class.
Like what we have done in class, we have the first hitting time 
$$T_{i\to i+1}=\mathbbm{1}[\mathcal{A}]+\mathbbm{1}[\overline{\mathcal{A}}](1+T_{i-1\to i}+T_{i_\to i+1})$$
where $\mathcal{A}$ represents the event that the first step is to the right.\\
Then by taking the expectations of both sides we have 
$$\mathbb{E}\left[T_{i\to i+1}\right]=\frac{1}{3}+\frac{2}{3}(1+\mathbb{E}\left[T_{i-1\to i}\right]+\mathbb{E}\left[T_{i\to i+1}\right])$$
equivalently,
$$\mathbb{E}\left[T_{i\to i+1}\right]=2\mathbb{E}\left[T_{i-1\to i}\right]+3$$
Then by simple calculation we derive $\mathbb{E}\left[T_{i\to i+1}\right]=2^{i+2}-3$,
by which we can further calculate that 
$$\mathbb{E}\left[T_{i\to n}\right]=\sum_{k=i}^{n-1}\mathbb{E}\left[T_{k\to k+1}\right]=\sum_{k=i}^{n-1}(2^{k+2}-3)=2^{n+2}-2^{i+2}-3n+3i\leq 2^{n+2}$$
So the expectation of first hitting time of $n$ from $i$ is less than $2^{n+2}$,
which means that to reach a 0.99 correct probability, 
it is sufficient if we do the random flipping  $400\cdot2^n$ times.
Meanwhile it is impossible for us to finish this task within $O(2^n)$ times by our analysis,
so we need to do the random flipping operation for $\Theta(2^n)$ times.

\newpage
\section{Acknowledgements}
\subsection*{Q1.1}
The idea of proving a finite irreducible markov chain is from lecture 5 of STAT253/317, University of Chicago.
\subsection*{Q1.2-1.3}
Actually from lecture notes previous year.
\subsection*{Q2.4-2.6}
\end{document}
