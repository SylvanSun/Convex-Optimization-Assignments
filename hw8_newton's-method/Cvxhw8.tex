\documentclass[12pt,letterpaper]{article}
\usepackage{fullpage}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{xfrac}
\usepackage{pdfpages}
\usepackage{float} 
\usepackage{subfigure} 

\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}
\linespread{1.1}
 
\renewcommand\lstlistingname{Algorithm}
\renewcommand\lstlistlistingname{Algorithms}
\def\lstlistingautorefname{Alg.}

\lstdefinestyle{Python}{
    language        = Python,
    frame           = lines, 
    basicstyle      = \footnotesize,
    keywordstyle    = \color{blue},
    stringstyle     = \color{green},
    commentstyle    = \color{red}\ttfamily
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}

% Edit these as appropriate
\newcommand\course{ConvexOptimization}
\newcommand\hwnumber{8}                  % <-- homework number
\newcommand\NetIDa{SUN Yilin}           % <-- NetID of person #1
\newcommand\NetIDb{520030910361}           % <-- NetID of person #2 (Comment this line out for problem sets)

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\NetIDa}
\lhead{\NetIDa\\\NetIDb}                 % <-- Comment this line out for problem sets (make sure you are person #1)
\chead{\textbf{\Large Homework \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}
\section{}
\subsection*{(a)}
\begin{figure}[htbp]
\centering
\subfigure[trajectory with initial point (-1.5,1)]{
\label{tr1a}
\includegraphics[width=0.45\textwidth]{nt_traces_1a.pdf}}
\subfigure[gap with initial point (-1.5,1)]{
\label{gap1a}
\includegraphics[width=0.45\textwidth]{nt_gap_1a.pdf}}
\caption{trajectories and gaps for part (a)}
\label{trandgap1a}
\end{figure}
The solution is $(x_1,x_2)=(-0.3466,0)$ and the optimal value is 2.56. Number of iterations is only 4.

\subsection*{(b)}
\begin{figure}[htbp]
\centering
\subfigure[trajectory with initial point (1.5,1)]{
\label{tr1b}
\includegraphics[width=0.45\textwidth]{nt_traces_1b.pdf}}
\subfigure[gap with initial point (1.5,1)]{
\label{gap1b}
\includegraphics[width=0.45\textwidth]{nt_gap_1b.pdf}}
\caption{trajectories and gaps for part (b)}
\label{trandgap1b}
\end{figure}
With another initial point the solution is $(x_1,x_2)=(-0.3464,0)$ and the optimal value is 2.56. Number of iterations is 7 this time.

\section{}
\subsection*{(a)}
We have shown that 
$$\frac{\partial f}{\partial \boldsymbol{w}}=(\sum_{i=1}^{m}\frac{-y_i\boldsymbol{x_{i}}e^{-y_i\boldsymbol{x_{i}^{T}w}}}{1+e^{-y_i\boldsymbol{x_{i}^{T}w}}})^T$$
Or equivalently we can write that component-wise
$$\frac{\partial f}{\partial w_k}=\sum_{i=1}^{m}\frac{-y_ix_{ik}e^{-y_i\boldsymbol{x_{i}^{T}w}}}{1+e^{-y_i\boldsymbol{x_{i}^{T}w}}}$$
Then we take second derivative directly and get
$$\frac{\partial^2 f}{\partial w_k\partial w_j}=\sum_{i=1}^{m}\frac{y_i^2x_{i_k}x_{i_j}e^{-y_i\boldsymbol{x_{i}^{T}w}}(1+e^{-y_i\boldsymbol{x_{i}^{T}w}})-y_i^2x_{i_k}x_{i_j}e^{-y_i\boldsymbol{x_{i}^{T}w}}e^{-y_i\boldsymbol{x_{i}^{T}w}}}{(1+e^{-y_i\boldsymbol{x_{i}^{T}w}})^2}$$
$$\frac{\partial^2 f}{\partial w_k\partial w_j}=\sum_{i=1}^{m}\frac{e^{-y_i\boldsymbol{x_{i}^{T}w}}}{(1+e^{-y_i\boldsymbol{x_{i}^{T}w}})^2}x_{i_k}x_{i_j}$$
$$\frac{\partial^2 f}{\partial w_k\partial w_j}=\sum_{i=1}^{m}\sigma'(y_i\boldsymbol{x_{i}^{T}w}) x_{i_k}x_{i_j}$$
And that is the element of the k-th row and j-th column in the Hessian Matrix. If we write that in the matrix form we can get the Hessian Matrix. Which is 
$$\nabla^2f(\boldsymbol{w})=\sum_{i=1}^{m}\sigma'(y_i\boldsymbol{x_{i}^{T}w})\boldsymbol{x}_i\boldsymbol{x}_i^T$$
\subsection*{(b)}
The optimal $\boldsymbol{w}^*$ given by damped Newton's method is $(-1.47, 4.44, -4.38)$ and the optimal value is 2.88. The number of iterations in the outer loop and the total number of iterations in the inner loop are both 9. The gaps and stepsizes are below.
\begin{figure}[htbp]
\centering
\subfigure[gap with dnt]{
\label{gap2b}
\includegraphics[width=0.45\textwidth]{dnt_gap.pdf}}
\subfigure[stepsize with dnt]{
\label{ss2b}
\includegraphics[width=0.45\textwidth]{dnt_ss.pdf}}
\caption{gap and stepsize with damped Newton's method for part (b)}
\label{2b}
\end{figure}

\subsection*{(c)}
If we use pure Newton's method with the same initial point we cannot do gradient descent because the Hessian Matrix at some point is nearly not invertible where the Newton step goes to infinity, consequently we cannot do the iteration. \\
But we must note that this does not happen for all initial points. If we choose some other initial point, pure Newton's method actually works. For example if we choose initial point $\boldsymbol{w}_0=(-1.0,3.0,-3.0)$, pure Newton's method gives us exactly the same optima as damped Newton's method with only 6 iterations.(Can check the result by running q2.py)

\section{}
\subsection*{(a)}
Since this is a univariate funtion, we take the derivatives. $f'(x)=4(x-a)^3$ and $f''(x)=12(x-a)^2$. Then the Newton step is simply $x_{k+1}=\frac{2}{3}x_{k}+\frac{1}{3}a$. 
\subsection*{(b)}
$y_{k+1}=|x_{k+1}-a|=|\frac{2}{3}x_k+\frac{1}{3}a-a|=|\frac{2}{3}x_k-\frac{2}{3}a|=\frac{2}{3}y_k$
\subsection*{(c)}
From $y_{k+1}=\frac{2}{3}y_{k}$ we can easily get $y_k=(\frac{2}{3})^{k}y_0$ or equivalently $|x_k-a|=(\frac{2}{3})^k|x_0-a|$. So $x_k$ goes to $a$ exponentially fast as $k$ goes to infinity.
\section{}

\subsection*{(a)}
\begin{figure}[htbp]
\centering
\subfigure[trajectory with $\lambda$=2]{
\label{tr4a}
\includegraphics[width=0.45\textwidth]{ista_traces_lambda2.pdf}}
\subfigure[gap with $\lambda$=2]{
\label{gap4a}
\includegraphics[width=0.45\textwidth]{ista_gap_lambda2.pdf}}
\caption{ISTA trajectory and gap for part (a) }
\label{4a}
\end{figure}
The optima is $\boldsymbol{w}^*=(1,0)$ with function value $6.5$. The number of iterations is 169.
\subsection*{(b)}
\begin{figure}[htbp]
\centering
\subfigure[trajectory with $\lambda$=1]{
\label{tr4b}
\includegraphics[width=0.45\textwidth]{ista_traces_lambda1.pdf}}
\subfigure[gap with $\lambda$=1]{
\label{gap4b}
\includegraphics[width=0.45\textwidth]{ista_gap_lambda1.pdf}}
\caption{ISTA trajectory and gap for part (b) }
\label{4b}
\end{figure}
The optima is $\boldsymbol{w}^*=(1.25,1)$ with function value $4.875$. The number of iterations is 169.\\
We can see that with a smaller $\lambda$ there are no zero components in $\boldsymbol{w}^*$.
\subsection*{(c)}

\begin{figure}[htbp]
\centering
\subfigure[trajectory with $\lambda$=6]{
\label{tr4c}
\includegraphics[width=0.45\textwidth]{ista_traces_lambda6.pdf}}
\subfigure[gap with $\lambda$=6]{
\label{gap4c}
\includegraphics[width=0.45\textwidth]{ista_gap_lambda6.pdf}}
\caption{ISTA trajectory and gap for part (c) }
\label{4c}
\end{figure}
The optima is $\boldsymbol{w}^*=(0,0)$ with function value $8.5$. The number of iterations is 38. We can see that both components of $\boldsymbol{w}^*$ are zero.\\
From this problem we can see $\boldsymbol{w}^*$ gets more zero components as $\lambda$ goes larger.
\end{document}